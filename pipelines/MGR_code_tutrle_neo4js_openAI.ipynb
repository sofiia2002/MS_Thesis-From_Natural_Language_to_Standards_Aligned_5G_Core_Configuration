{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fvefgy8IBgTU"
      },
      "outputs": [],
      "source": [
        "OPEN_AI_SECRET_KEY=\"example\"\n",
        "\n",
        "NEO4J_URI=\"neo4j+s://example.databases.neo4j.io\"\n",
        "NEO4J_USERNAME=\"neo4j\"\n",
        "NEO4J_PASSWORD=\"example\"\n",
        "AURA_INSTANCEID=\"example\"\n",
        "AURA_INSTANCENAME=\"Instance0\"\n",
        "\n",
        "NEO4J_DB = \"neo4j\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMYYhbh8xPbb"
      },
      "source": [
        "Importing turtle file into AuraDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dcyqxv4uyWY3",
        "outputId": "8f03ae02-f029-4470-c29b-6604fcda5284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/565.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m563.2/565.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.1/565.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/313.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m307.2/313.2 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install rdflib rdflib-neo4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "v48xb2ke4vSn",
        "outputId": "4b96956a-42d1-4ad5-c907-32c927c9d2d3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fbf545b6-cfff-4532-910e-e44e25669f7b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fbf545b6-cfff-4532-910e-e44e25669f7b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving yang_rule_no_mandatory_on_key.ttl to yang_rule_no_mandatory_on_key.ttl\n"
          ]
        }
      ],
      "source": [
        "# importing ttl file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "ttl_path = list(uploaded.keys())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEvxbSWqyFES",
        "outputId": "bd856e26-26a2-4d11-c9e5-8d8752c90ef0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uniqueness constraint on :Resource(uri) found. \n",
            "                \n",
            "                \n",
            "The store is now: Open\n",
            "Uniqueness constraint on :Resource(uri) found. \n",
            "                \n",
            "                \n",
            "The store is now: Open\n",
            "Triples loaded into Neo4j via RDFLib: 0\n",
            "The store is now: Closed\n",
            "IMPORTED 25 TRIPLES\n"
          ]
        }
      ],
      "source": [
        "# Ingest Turtle into Aura (or any Neo4j) with RDFLib-Neo4j\n",
        "from rdflib import Graph\n",
        "from rdflib_neo4j import Neo4jStore, Neo4jStoreConfig, HANDLE_VOCAB_URI_STRATEGY\n",
        "\n",
        "config = Neo4jStoreConfig(\n",
        "    auth_data={\"uri\": NEO4J_URI, \"database\": NEO4J_DB, \"user\": NEO4J_USERNAME, \"pwd\": NEO4J_PASSWORD},\n",
        "    handle_vocab_uri_strategy=HANDLE_VOCAB_URI_STRATEGY.IGNORE,  # or SHORTEN/MAP/KEEP\n",
        "    batching=True,  # optional: buffer writes for speed; remember to close()\n",
        ")\n",
        "\n",
        "g = Graph(store=Neo4jStore(config=config))\n",
        "\n",
        "# Auto-create the required uniqueness constraint if missing:\n",
        "g.open(configuration=None, create=True)  # creates CONSTRAINT on :Resource(uri)\n",
        "\n",
        "# Parse from local file:\n",
        "g.parse(ttl_path, format=\"turtle\")       # or format=\"ttl\"\n",
        "\n",
        "# Or parse directly from a URL instead:\n",
        "# g.parse(\"https://example.com/your.ttl\", format=\"turtle\")\n",
        "\n",
        "print(\"Triples loaded into Neo4j via RDFLib:\", len(g))\n",
        "g.close(True)  # commit pending buffered writes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBm4jStx-uQ-"
      },
      "source": [
        "Adding usage of LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ue3TXID6kBw",
        "outputId": "45e493f5-4e71-4e87-a004-76d69cf612d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.12.0 requires tenacity<9.0.0,>=8.0.0, but you have tenacity 9.1.2 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install modern LangChain split packages\n",
        "!pip -q install langchain langchain-community langchain-openai langchain-neo4j neo4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5u-37Hv_VX_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPEN_AI_SECRET_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n55mqUwpGEo8"
      },
      "outputs": [],
      "source": [
        "EMBED_MODEL = \"text-embedding-3-large\"   # or \"text-embedding-3-small\"\n",
        "CHAT_MODEL  = \"gpt-5\"              # or \"gpt-4o\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1RfNQSfGMU3",
        "outputId": "867ff1d4-fb6c-4fb4-9875-4bc357cdeeda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neo4j OK: True\n"
          ]
        }
      ],
      "source": [
        "# Sanity check\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
        "with driver.session() as s:\n",
        "    result = s.run(\"RETURN 1 AS ok\").single()\n",
        "print(\"Neo4j OK:\", result[\"ok\"] == 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqj1AepPGNhI",
        "outputId": "0227b315-2d66-49ee-9fad-d06e17b86918"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector store ready (existing graph).\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_neo4j import Neo4jVector\n",
        "\n",
        "emb = OpenAIEmbeddings(model=EMBED_MODEL)\n",
        "\n",
        "# configure your label + text properties here\n",
        "DOC_NODE_LABEL = \"Document\"                   # <-- change to your label\n",
        "TEXT_PROPS     = [\"title\", \"content\"]         # <-- change to your text fields\n",
        "INDEX_NAME     = \"docs_embedding\"             # Neo4j vector index name\n",
        "EMB_PROP       = \"embedding\"                  # property to store vectors\n",
        "KEYWORD_INDEX  = \"docs_keyword\"               # optional: for hybrid search\n",
        "\n",
        "vstore = Neo4jVector.from_existing_graph(\n",
        "    embedding=emb,\n",
        "    url=NEO4J_URI,\n",
        "    username=NEO4J_USERNAME,\n",
        "    password=NEO4J_PASSWORD,\n",
        "    node_label=DOC_NODE_LABEL,\n",
        "    text_node_properties=TEXT_PROPS,\n",
        "    embedding_node_property=EMB_PROP,\n",
        "    index_name=INDEX_NAME,\n",
        "    keyword_index_name=KEYWORD_INDEX,   # keep if you want hybrid search\n",
        "    search_type=\"hybrid\"                # or \"vector\"\n",
        ")\n",
        "\n",
        "print(\"Vector store ready (existing graph).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBaF75q8G5xi",
        "outputId": "6703fa08-a3ac-4cdd-f039-ca85d3456834"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: protocol)} {position: line: 10, column: 25, offset: 243} for query: \"\\n    MATCH (a)-[r]->(b)\\n    WITH\\n      coalesce(\\n        a.name, a.id, a.title, a.label, a.shortName, a.code, elementId(a)\\n      ) AS left_any,\\n      head(labels(a)) AS left_label,\\n      type(r) AS rel,\\n      coalesce(\\n        r.name, r.id, r.protocol, r.role, ''   // add r.interface here if you *do* have it\\n      ) AS r_any,\\n      coalesce(\\n        b.name, b.id, b.title, b.label, b.shortName, b.code, elementId(b)\\n      ) AS right_any,\\n      head(labels(b)) AS right_label\\n    WITH\\n      toString(left_any)  AS left,\\n      coalesce(left_label,'?')   AS left_label,\\n      rel,\\n      toString(r_any)     AS rname,\\n      toString(right_any) AS right,\\n      coalesce(right_label,'?')  AS right_label\\n    RETURN\\n      'Left: ' + left + ' (' + left_label + ')' +\\n      '\\nRel: ' + rel +\\n      CASE WHEN rname IS NOT NULL AND rname <> '' THEN ' [' + rname + ']' ELSE '' END +\\n      '\\nRight: ' + right + ' (' + right_label + ')' AS text,\\n      {left:left, right:right, rel:rel, rname:rname, left_label:left_label, right_label:right_label} AS meta\\n    LIMIT $limit\\n    \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: code)} {position: line: 13, column: 56, offset: 399} for query: \"\\n    MATCH (a)-[r]->(b)\\n    WITH\\n      coalesce(\\n        a.name, a.id, a.title, a.label, a.shortName, a.code, elementId(a)\\n      ) AS left_any,\\n      head(labels(a)) AS left_label,\\n      type(r) AS rel,\\n      coalesce(\\n        r.name, r.id, r.protocol, r.role, ''   // add r.interface here if you *do* have it\\n      ) AS r_any,\\n      coalesce(\\n        b.name, b.id, b.title, b.label, b.shortName, b.code, elementId(b)\\n      ) AS right_any,\\n      head(labels(b)) AS right_label\\n    WITH\\n      toString(left_any)  AS left,\\n      coalesce(left_label,'?')   AS left_label,\\n      rel,\\n      toString(r_any)     AS rname,\\n      toString(right_any) AS right,\\n      coalesce(right_label,'?')  AS right_label\\n    RETURN\\n      'Left: ' + left + ' (' + left_label + ')' +\\n      '\\nRel: ' + rel +\\n      CASE WHEN rname IS NOT NULL AND rname <> '' THEN ' [' + rname + ']' ELSE '' END +\\n      '\\nRight: ' + right + ' (' + right_label + ')' AS text,\\n      {left:left, right:right, rel:rel, rname:rname, left_label:left_label, right_label:right_label} AS meta\\n    LIMIT $limit\\n    \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: shortName)} {position: line: 5, column: 43, offset: 91} for query: \"\\n    MATCH (a)-[r]->(b)\\n    WITH\\n      coalesce(\\n        a.name, a.id, a.title, a.label, a.shortName, a.code, elementId(a)\\n      ) AS left_any,\\n      head(labels(a)) AS left_label,\\n      type(r) AS rel,\\n      coalesce(\\n        r.name, r.id, r.protocol, r.role, ''   // add r.interface here if you *do* have it\\n      ) AS r_any,\\n      coalesce(\\n        b.name, b.id, b.title, b.label, b.shortName, b.code, elementId(b)\\n      ) AS right_any,\\n      head(labels(b)) AS right_label\\n    WITH\\n      toString(left_any)  AS left,\\n      coalesce(left_label,'?')   AS left_label,\\n      rel,\\n      toString(r_any)     AS rname,\\n      toString(right_any) AS right,\\n      coalesce(right_label,'?')  AS right_label\\n    RETURN\\n      'Left: ' + left + ' (' + left_label + ')' +\\n      '\\nRel: ' + rel +\\n      CASE WHEN rname IS NOT NULL AND rname <> '' THEN ' [' + rname + ']' ELSE '' END +\\n      '\\nRight: ' + right + ' (' + right_label + ')' AS text,\\n      {left:left, right:right, rel:rel, rname:rname, left_label:left_label, right_label:right_label} AS meta\\n    LIMIT $limit\\n    \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: code)} {position: line: 5, column: 56, offset: 104} for query: \"\\n    MATCH (a)-[r]->(b)\\n    WITH\\n      coalesce(\\n        a.name, a.id, a.title, a.label, a.shortName, a.code, elementId(a)\\n      ) AS left_any,\\n      head(labels(a)) AS left_label,\\n      type(r) AS rel,\\n      coalesce(\\n        r.name, r.id, r.protocol, r.role, ''   // add r.interface here if you *do* have it\\n      ) AS r_any,\\n      coalesce(\\n        b.name, b.id, b.title, b.label, b.shortName, b.code, elementId(b)\\n      ) AS right_any,\\n      head(labels(b)) AS right_label\\n    WITH\\n      toString(left_any)  AS left,\\n      coalesce(left_label,'?')   AS left_label,\\n      rel,\\n      toString(r_any)     AS rname,\\n      toString(right_any) AS right,\\n      coalesce(right_label,'?')  AS right_label\\n    RETURN\\n      'Left: ' + left + ' (' + left_label + ')' +\\n      '\\nRel: ' + rel +\\n      CASE WHEN rname IS NOT NULL AND rname <> '' THEN ' [' + rname + ']' ELSE '' END +\\n      '\\nRight: ' + right + ' (' + right_label + ')' AS text,\\n      {left:left, right:right, rel:rel, rname:rname, left_label:left_label, right_label:right_label} AS meta\\n    LIMIT $limit\\n    \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: shortName)} {position: line: 13, column: 43, offset: 386} for query: \"\\n    MATCH (a)-[r]->(b)\\n    WITH\\n      coalesce(\\n        a.name, a.id, a.title, a.label, a.shortName, a.code, elementId(a)\\n      ) AS left_any,\\n      head(labels(a)) AS left_label,\\n      type(r) AS rel,\\n      coalesce(\\n        r.name, r.id, r.protocol, r.role, ''   // add r.interface here if you *do* have it\\n      ) AS r_any,\\n      coalesce(\\n        b.name, b.id, b.title, b.label, b.shortName, b.code, elementId(b)\\n      ) AS right_any,\\n      head(labels(b)) AS right_label\\n    WITH\\n      toString(left_any)  AS left,\\n      coalesce(left_label,'?')   AS left_label,\\n      rel,\\n      toString(r_any)     AS rname,\\n      toString(right_any) AS right,\\n      coalesce(right_label,'?')  AS right_label\\n    RETURN\\n      'Left: ' + left + ' (' + left_label + ')' +\\n      '\\nRel: ' + rel +\\n      CASE WHEN rname IS NOT NULL AND rname <> '' THEN ' [' + rname + ']' ELSE '' END +\\n      '\\nRight: ' + right + ' (' + right_label + ')' AS text,\\n      {left:left, right:right, rel:rel, rname:rname, left_label:left_label, right_label:right_label} AS meta\\n    LIMIT $limit\\n    \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: role)} {position: line: 10, column: 37, offset: 255} for query: \"\\n    MATCH (a)-[r]->(b)\\n    WITH\\n      coalesce(\\n        a.name, a.id, a.title, a.label, a.shortName, a.code, elementId(a)\\n      ) AS left_any,\\n      head(labels(a)) AS left_label,\\n      type(r) AS rel,\\n      coalesce(\\n        r.name, r.id, r.protocol, r.role, ''   // add r.interface here if you *do* have it\\n      ) AS r_any,\\n      coalesce(\\n        b.name, b.id, b.title, b.label, b.shortName, b.code, elementId(b)\\n      ) AS right_any,\\n      head(labels(b)) AS right_label\\n    WITH\\n      toString(left_any)  AS left,\\n      coalesce(left_label,'?')   AS left_label,\\n      rel,\\n      toString(r_any)     AS rname,\\n      toString(right_any) AS right,\\n      coalesce(right_label,'?')  AS right_label\\n    RETURN\\n      'Left: ' + left + ' (' + left_label + ')' +\\n      '\\nRel: ' + rel +\\n      CASE WHEN rname IS NOT NULL AND rname <> '' THEN ' [' + rname + ']' ELSE '' END +\\n      '\\nRight: ' + right + ' (' + right_label + ')' AS text,\\n      {left:left, right:right, rel:rel, rname:rname, left_label:left_label, right_label:right_label} AS meta\\n    LIMIT $limit\\n    \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Built 3524 chunk(s).\n",
            "Example:\n",
            " Left: 4:8606e1fe-fb64-473a-89ee-50c8506f5ac1:1 (Resource)\n",
            "Rel: domain\n",
            "Right: 4:8606e1fe-fb64-473a-89ee-50c8506f5ac1:986 (Resource)\n",
            "Vector store ready (chunks from triples).\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_neo4j import Neo4jVector\n",
        "\n",
        "def load_graph_chunks(limit=8000):\n",
        "    \"\"\"\n",
        "    Robust chunk builder: avoids missing property warnings\n",
        "    and guarantees non-null strings for page_content.\n",
        "    Adjust the property candidates to match your schema.\n",
        "    \"\"\"\n",
        "    q = \"\"\"\n",
        "    MATCH (a)-[r]->(b)\n",
        "    WITH\n",
        "      coalesce(\n",
        "        a.name, a.id, a.title, a.label, a.shortName, a.code, elementId(a)\n",
        "      ) AS left_any,\n",
        "      head(labels(a)) AS left_label,\n",
        "      type(r) AS rel,\n",
        "      coalesce(\n",
        "        r.name, r.id, r.protocol, r.role, ''   // add r.interface here if you *do* have it\n",
        "      ) AS r_any,\n",
        "      coalesce(\n",
        "        b.name, b.id, b.title, b.label, b.shortName, b.code, elementId(b)\n",
        "      ) AS right_any,\n",
        "      head(labels(b)) AS right_label\n",
        "    WITH\n",
        "      toString(left_any)  AS left,\n",
        "      coalesce(left_label,'?')   AS left_label,\n",
        "      rel,\n",
        "      toString(r_any)     AS rname,\n",
        "      toString(right_any) AS right,\n",
        "      coalesce(right_label,'?')  AS right_label\n",
        "    RETURN\n",
        "      'Left: ' + left + ' (' + left_label + ')' +\n",
        "      '\\nRel: ' + rel +\n",
        "      CASE WHEN rname IS NOT NULL AND rname <> '' THEN ' [' + rname + ']' ELSE '' END +\n",
        "      '\\nRight: ' + right + ' (' + right_label + ')' AS text,\n",
        "      {left:left, right:right, rel:rel, rname:rname, left_label:left_label, right_label:right_label} AS meta\n",
        "    LIMIT $limit\n",
        "    \"\"\"\n",
        "    with driver.session() as s:\n",
        "        rows = s.run(q, limit=limit).data()\n",
        "\n",
        "    # Defensive: keep only rows that produced text\n",
        "    docs = [Document(page_content=r.get(\"text\", \"\"), metadata=r.get(\"meta\", {}))\n",
        "            for r in rows if r.get(\"text\")]\n",
        "    return docs\n",
        "\n",
        "docs = load_graph_chunks(limit=8000)\n",
        "print(f\"Built {len(docs)} chunk(s).\")\n",
        "if docs:\n",
        "    print(\"Example:\\n\", docs[0].page_content[:300])\n",
        "\n",
        "emb = OpenAIEmbeddings(model=EMBED_MODEL)\n",
        "\n",
        "vstore = Neo4jVector.from_documents(\n",
        "    documents=docs,\n",
        "    embedding=emb,\n",
        "    url=NEO4J_URI,\n",
        "    username=NEO4J_USERNAME,\n",
        "    password=NEO4J_PASSWORD,\n",
        "    # customize storage / indexes:\n",
        "    node_label=\"Chunk\",\n",
        "    text_node_property=\"text\",        # <-- singular\n",
        "    embedding_node_property=\"embedding\",\n",
        "    index_name=\"chunk_embedding\",\n",
        "    search_type=\"hybrid\",             # creates vector + keyword indexes\n",
        "    keyword_index_name=\"chunk_keyword\"\n",
        ")\n",
        "\n",
        "print(\"Vector store ready (chunks from triples).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHKXIBZZiyyi",
        "outputId": "19ae44ac-91d4-46a3-f745-1332c3a24370"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-922585009.py:51: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  resp = qa({\"query\": query})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: Enable each network function to declare the services it exposes, including version and supported protocols. \n",
            "\n",
            "module open5gs-nf-services {\n",
            "  yang-version 1.1;\n",
            "  namespace \"urn:open5gs:params:xml:ns:yang:open5gs-nf-services\";\n",
            "  prefix og-nfs;\n",
            "\n",
            "  organization \"Open5GS Community\";\n",
            "  contact\n",
            "    \"https://open5gs.org/\";\n",
            "  description\n",
            "    \"This module allows each 5GC network function (NF) to declare the services\n",
            "     it exposes, including the API version and supported protocols.\";\n",
            "\n",
            "  revision 2025-09-03 {\n",
            "    description\n",
            "      \"Initial revision.\";\n",
            "  }\n",
            "\n",
            "  typedef protocol-type {\n",
            "    type enumeration {\n",
            "      enum http2 {\n",
            "        description \"HTTP/2 (RFC 7540), typical for 3GPP SBI over TLS.\";\n",
            "      }\n",
            "      enum http1-1 {\n",
            "        description \"HTTP/1.1 (RFC 9112).\";\n",
            "      }\n",
            "      enum http3 {\n",
            "        description \"HTTP/3 (RFC 9114) over QUIC.\";\n",
            "      }\n",
            "    }\n",
            "    description\n",
            "      \"Finite set of supported application protocols for the exposed services.\";\n",
            "  }\n",
            "\n",
            "  container network-functions {\n",
            "    description\n",
            "      \"Catalog of NF instances and the services they expose.\";\n",
            "    list network-function {\n",
            "      key \"nf-id\";\n",
            "      description\n",
            "        \"An NF instance.\";\n",
            "      leaf nf-id {\n",
            "        type string;\n",
            "        description\n",
            "          \"Unique identifier of the NF instance (e.g., UUID).\";\n",
            "      }\n",
            "\n",
            "      list service {\n",
            "        key \"name version\";\n",
            "        description\n",
            "          \"A service exposed by this NF, keyed by its name and version.\";\n",
            "        leaf name {\n",
            "          type string;\n",
            "          description\n",
            "            \"Service name (e.g., Nnrf_NFDiscovery, Namf_Communication).\";\n",
            "        }\n",
            "        leaf version {\n",
            "          type string {\n",
            "            pattern 'v[0-9]+(\\.[0-9]+){0,2}';\n",
            "          }\n",
            "          description\n",
            "            \"API version label (e.g., v1, v1.1, v1.2.0).\";\n",
            "        }\n",
            "        leaf-list supported-protocols {\n",
            "          type protocol-type;\n",
            "          min-elements 1;\n",
            "          description\n",
            "            \"Protocols supported by this service. Use enumeration for finite, controlled values.\";\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "- (4:8606e1fe-fb64-473a-89ee-50c8506f5ac1:5702|exampleFor|Use YANG 'enumeration' type when values are finite and controlled (e.g., protocols).)\n",
            "- (4:7e579923-d560-44db-bb2f-34f3325899f2:412|isSupportedVia|4:7e579923-d560-44db-bb2f-34f3325899f2:1560)\n",
            "- (4:7e579923-d560-44db-bb2f-34f3325899f2:5702|exampleFor|Use YANG 'enumeration' type when values are finite and controlled (e.g., protocols).)\n",
            "- (4:7e579923-d560-44db-bb2f-34f3325899f2:518|isImplementedVia|4:7e579923-d560-44db-bb2f-34f3325899f2:1322)\n",
            "- (4:8606e1fe-fb64-473a-89ee-50c8506f5ac1:2089|canExpose|4:8606e1fe-fb64-473a-89ee-50c8506f5ac1:2076)\n",
            "- (4:8606e1fe-fb64-473a-89ee-50c8506f5ac1:2006|exposes|4:8606e1fe-fb64-473a-89ee-50c8506f5ac1:1525)\n",
            "\n",
            "Sources:\n",
            "- Left: 4:8606e1fe-fb64-473a-89ee-50c8506f5ac1:5702 (Resource)\n",
            "- Left: 4:7e579923-d560-44db-bb2f-34f3325899f2:412 (Resource)\n",
            "- Left: 4:7e579923-d560-44db-bb2f-34f3325899f2:5702 (Resource)\n",
            "- Left: 4:7e579923-d560-44db-bb2f-34f3325899f2:518 (Resource)\n",
            "- Left: 4:8606e1fe-fb64-473a-89ee-50c8506f5ac1:2089 (Resource)\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(model=CHAT_MODEL, temperature=0)\n",
        "\n",
        "# hybrid works well for acronyms (AMF/SMF/N2/N11/5QI); fallback to \"similarity\" if needed\n",
        "try:\n",
        "    retriever = vstore.as_retriever(search_type=\"hybrid\", search_kwargs={\"k\": 6})\n",
        "except Exception:\n",
        "    retriever = vstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
        "\n",
        "TELECOM_PROMPT = PromptTemplate.from_template(\n",
        "    \"\"\"You are a 5G/Open5GS expert. Your purpose is to translate high-level requirements\n",
        "    for a 5GCore network into a YANG configuration. Analyze carefully all of the requirements\n",
        "    for a YANG format and keep it strict. Ensure that YANG format follows all the rules to be\n",
        "    validated successfully by libyang tool.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "At the end, list bullet 'evidence lines' in the format (Left|Rel|Right).\"\"\"\n",
        ")\n",
        "\n",
        "# TELECOM_PROMPT = PromptTemplate.from_template(\n",
        "#     \"\"\"You are a 5G/Open5GS expert. Use standards-aware, precise language.\n",
        "# Expand acronyms on first use (e.g., AMF—Access and Mobility Management Function).\n",
        "# If interfaces appear, mention their purpose (e.g., N11—AMF↔SMF, session control).\n",
        "\n",
        "# Question:\n",
        "# {question}\n",
        "\n",
        "# Context:\n",
        "# {context}\n",
        "\n",
        "# Answer clearly. At the end, list 2–5 bullet 'evidence lines' in the format (Left|Rel|Right).\"\"\"\n",
        "# )\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    chain_type=\"stuff\",\n",
        "    chain_type_kwargs={\"prompt\": TELECOM_PROMPT},\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "query = \"Enable each network function to declare the services it exposes, including version and supported protocols.\"\n",
        "resp = qa({\"query\": query})\n",
        "\n",
        "print(\"Q:\", query, \"\\n\")\n",
        "print(resp[\"result\"])\n",
        "print(\"\\nSources:\")\n",
        "for d in resp[\"source_documents\"][:5]:\n",
        "    print(\"-\", (d.page_content.splitlines() or [d.page_content[:120]])[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJOBNa9V8ED6"
      },
      "source": [
        "Flow for comparing doc loading and knowledge graph code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hipJPkQa8Dkh",
        "outputId": "7519f0bc-94f7-4785-ba22-96d8de078546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchain-openai langchain-community faiss-cpu pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbSfsns-8LcV"
      },
      "outputs": [],
      "source": [
        "import os, time, glob, textwrap\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Reuse existing settings if you have them, else set defaults\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
        "assert OPENAI_API_KEY, \"Set OPENAI_API_KEY first.\"\n",
        "\n",
        "EMBED_MODEL = os.getenv(\"EMBED_MODEL\", \"text-embedding-3-small\")  # good default for speed/cost\n",
        "CHAT_MODEL  = os.getenv(\"CHAT_MODEL\",  \"gpt-4o-mini\")\n",
        "\n",
        "# If you already created vstore/qa for Neo4j earlier, we’ll reuse them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WbksS-M8VAz",
        "outputId": "23cfac52-d5b4-443d-f977-1bb3c3baa3e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 184 pages from 11 PDF(s).\n",
            "Chunks: 685\n",
            "PDF vector store ready.\n"
          ]
        }
      ],
      "source": [
        "PDF_DIR = \"./pdfs\"     # <-- point to your folder of PDFs\n",
        "PDF_GLOB = \"*.pdf\"\n",
        "\n",
        "# 3a) Load PDFs\n",
        "pdf_files = sorted(glob.glob(os.path.join(PDF_DIR, PDF_GLOB)))\n",
        "assert pdf_files, f\"No PDFs found under {PDF_DIR}. Put some files there or change PDF_DIR.\"\n",
        "\n",
        "raw_docs = []\n",
        "for f in pdf_files:\n",
        "    try:\n",
        "        loader = PyPDFLoader(f)\n",
        "        raw_docs.extend(loader.load())\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: failed to load {f}: {e}\")\n",
        "\n",
        "print(f\"Loaded {len(raw_docs)} pages from {len(pdf_files)} PDF(s).\")\n",
        "\n",
        "# 3b) Chunking\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "pdf_docs = splitter.split_documents(raw_docs)\n",
        "# add simple, consistent metadata for debugging\n",
        "for d in pdf_docs:\n",
        "    d.metadata[\"source_file\"] = d.metadata.get(\"source\") or d.metadata.get(\"file_path\")\n",
        "    d.metadata[\"page\"] = d.metadata.get(\"page\", d.metadata.get(\"page_number\"))\n",
        "\n",
        "print(f\"Chunks: {len(pdf_docs)}\")\n",
        "\n",
        "# 3c) Embeddings + FAISS vector store\n",
        "emb_pdf = OpenAIEmbeddings(model=EMBED_MODEL)\n",
        "pdf_vstore = FAISS.from_documents(pdf_docs, emb_pdf)\n",
        "\n",
        "# Retriever for PDF\n",
        "pdf_retriever = pdf_vstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
        "print(\"PDF vector store ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srb68T---25C",
        "outputId": "3d9f5c71-cab7-460f-d947-c061cc318ef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAG chains ready (Neo4j + PDF).\n"
          ]
        }
      ],
      "source": [
        "# Neo4j retriever/qa: try to reuse if already defined; else raise a helpful error\n",
        "try:\n",
        "    retriever_neo4j = vstore.as_retriever(\n",
        "        search_type=\"similarity\",                 # <- allowed by VectorStoreRetriever\n",
        "        search_kwargs={\"k\": 6, \"search_type\": \"hybrid\"}  # <- passed through to Neo4jVector\n",
        "    )\n",
        "except Exception:\n",
        "    # fallback to pure vector if hybrid isn't available (e.g., no keyword index)\n",
        "    retriever_neo4j = vstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
        "\n",
        "llm = ChatOpenAI(model=CHAT_MODEL, temperature=0)\n",
        "\n",
        "TELECOM_PROMPT = PromptTemplate.from_template(\n",
        "    \"\"\"You are a 5G/Open5GS expert. Your purpose is to translate high-level requirements\n",
        "    for a 5GCore network into a YANG configuration. Analyze carefully all of the requirements\n",
        "    for a YANG format and keep it strict. Ensure that YANG format follows all the rules to be\n",
        "    validated successfully by libyang tool.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "At the end, list bullet 'evidence lines' in the format (Left|Rel|Right).\"\"\"\n",
        ")\n",
        "\n",
        "qa_pdf = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=pdf_retriever,\n",
        "    chain_type=\"stuff\",\n",
        "    chain_type_kwargs={\"prompt\": TELECOM_PROMPT},\n",
        "    return_source_documents=True,\n",
        ")\n",
        "\n",
        "qa_neo4j = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever_neo4j,\n",
        "    chain_type=\"stuff\",\n",
        "    chain_type_kwargs={\"prompt\": TELECOM_PROMPT},\n",
        "    return_source_documents=True,\n",
        ")\n",
        "\n",
        "print(\"RAG chains ready (Neo4j + PDF).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaUrPtdR-4fN"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class RunResult:\n",
        "    pipeline: str\n",
        "    answer: str\n",
        "    time_s: float\n",
        "    sources: List[Dict[str, Any]]\n",
        "\n",
        "def _summarize_sources(sources: List[Any], kind: str) -> List[str]:\n",
        "    out = []\n",
        "    if kind == \"pdf\":\n",
        "        for d in sources[:6]:\n",
        "            src = d.metadata.get(\"source_file\", \"unknown.pdf\")\n",
        "            page = d.metadata.get(\"page\", \"?\")\n",
        "            first = (d.page_content or \"\").strip().replace(\"\\n\", \" \")\n",
        "            out.append(f\"{os.path.basename(src)}:p{page} — {first[:160]}{'…' if len(first)>160 else ''}\")\n",
        "    else:  # neo4j\n",
        "        for d in sources[:6]:\n",
        "            first = (d.page_content or \"\").strip().splitlines()\n",
        "            first_line = first[0] if first else \"\"\n",
        "            out.append(first_line[:180] + (\"…\" if len(first_line) > 180 else \"\"))\n",
        "    return out\n",
        "\n",
        "def ask_both(question: str, judge: bool = True) -> Dict[str, Any]:\n",
        "    # Neo4j\n",
        "    t0 = time.time()\n",
        "    neo = qa_neo4j({\"query\": question})\n",
        "    neo_t = time.time() - t0\n",
        "\n",
        "    # PDF\n",
        "    t1 = time.time()\n",
        "    pdf = qa_pdf({\"query\": question})\n",
        "    pdf_t = time.time() - t1\n",
        "\n",
        "    neo_sources = _summarize_sources(neo[\"source_documents\"], \"neo4j\")\n",
        "    pdf_sources = _summarize_sources(pdf[\"source_documents\"], \"pdf\")\n",
        "\n",
        "    result = {\n",
        "        \"neo4j\": RunResult(\"neo4j\", neo[\"result\"], neo_t, neo_sources),\n",
        "        \"pdf\":   RunResult(\"pdf\",   pdf[\"result\"], pdf_t, pdf_sources)\n",
        "    }\n",
        "\n",
        "    if not judge:\n",
        "        return result\n",
        "\n",
        "    # LLM-as-judge: which is more correct/grounded *given the retrieved contexts*?\n",
        "    judge_prompt = PromptTemplate.from_template(\n",
        "        \"\"\"You are grading two answers to the same question using only the provided contexts.\n",
        "Score on: factual correctness, grounding to context, telecom clarity, YANG format correctness.\n",
        "\n",
        "For both you are a 5G/Open5GS expert. Your purpose is to translate high-level requirements\n",
        "for a 5GCore network into a YANG configuration. Analyze carefully all of the requirements\n",
        "for a YANG format and keep it strict. Ensure that YANG format follows all the rules to be\n",
        "validated successfully by libyang tool. Answer should include a YANG template and a short\n",
        "description of the result.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer A (Neo4j):\n",
        "{ans_a}\n",
        "\n",
        "Context A (Neo4j top sources):\n",
        "{ctx_a}\n",
        "\n",
        "Answer B (PDF):\n",
        "{ans_b}\n",
        "\n",
        "Context B (PDF top sources):\n",
        "{ctx_b}\n",
        "\n",
        "Respond as JSON with fields:\n",
        "- \"winner\": one of [\"neo4j\",\"pdf\",\"tie\"]\n",
        "- \"rationale\": 1-3 sentences explaining the decision.\n",
        "\"\"\"\n",
        "    )\n",
        "    judge_llm = ChatOpenAI(model=CHAT_MODEL, temperature=0)\n",
        "    judge_in = judge_prompt.format(\n",
        "        question=question,\n",
        "        ans_a=result[\"neo4j\"].answer,\n",
        "        ctx_a=\"\\n\".join(result[\"neo4j\"].sources),\n",
        "        ans_b=result[\"pdf\"].answer,\n",
        "        ctx_b=\"\\n\".join(result[\"pdf\"].sources),\n",
        "    )\n",
        "    j = judge_llm.invoke(judge_in).content\n",
        "    result[\"judge_raw\"] = j\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGYBbT_5-6kV"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def show_comparison(question: str, judge: bool = True):\n",
        "    res = ask_both(question, judge=judge)\n",
        "\n",
        "    neo = res[\"neo4j\"]\n",
        "    pdf = res[\"pdf\"]\n",
        "\n",
        "    print(\"=\"*90)\n",
        "    print(\"QUESTION:\")\n",
        "    print(question)\n",
        "    print(\"=\"*90)\n",
        "    print(\"[Neo4j] time: %.2fs\" % neo.time_s)\n",
        "    print(textwrap.fill(neo.answer, width=100))\n",
        "    print(\"\\nSources (Neo4j):\")\n",
        "    for s in neo.sources:\n",
        "        print(\" •\", s)\n",
        "\n",
        "    print(\"\\n\" + \"-\"*90 + \"\\n\")\n",
        "\n",
        "    print(\"[PDF]   time: %.2fs\" % pdf.time_s)\n",
        "    print(textwrap.fill(pdf.answer, width=100))\n",
        "    print(\"\\nSources (PDF):\")\n",
        "    for s in pdf.sources:\n",
        "        print(\" •\", s)\n",
        "\n",
        "    if judge and \"judge_raw\" in res:\n",
        "        print(\"\\n\" + \"=\"*90)\n",
        "        print(\"LLM JUDGE:\")\n",
        "        try:\n",
        "            j = json.loads(res[\"judge_raw\"])\n",
        "        except Exception:\n",
        "            print(res[\"judge_raw\"])\n",
        "        else:\n",
        "            print(\"Winner:\", j.get(\"winner\"))\n",
        "            print(\"Rationale:\", j.get(\"rationale\"))\n",
        "\n",
        "# Example:\n",
        "# show_comparison(\"Which network function coordinates UE registration and which interfaces are involved?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARREqcF6-9rV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def max_grounding_similarity(answer: str, retrieved_docs: List[Any], emb: OpenAIEmbeddings) -> float:\n",
        "    ans_vec = np.array(emb.embed_query(answer), dtype=float)\n",
        "    ctx_vecs = np.array([emb.embed_query(d.page_content[:1000]) for d in retrieved_docs], dtype=float)\n",
        "    # cosine similarity\n",
        "    sims = (ctx_vecs @ ans_vec) / (np.linalg.norm(ctx_vecs, axis=1) * np.linalg.norm(ans_vec) + 1e-9)\n",
        "    return float(np.max(sims)) if len(sims) else 0.0\n",
        "\n",
        "def compare_with_scores(question: str):\n",
        "    res = ask_both(question, judge=False)\n",
        "    neo = res[\"neo4j\"]; pdf = res[\"pdf\"]\n",
        "\n",
        "    # reuse the same embedder model used for PDF; it’s fine for a relative score\n",
        "    emb_eval = emb_pdf\n",
        "\n",
        "    # We need the full docs, not the summarized strings → rerun each quickly to capture docs\n",
        "    neo_full = qa_neo4j({\"query\": question})\n",
        "    pdf_full = qa_pdf({\"query\": question})\n",
        "\n",
        "    neo_score = max_grounding_similarity(neo_full[\"result\"], neo_full[\"source_documents\"], emb_eval)\n",
        "    pdf_score = max_grounding_similarity(pdf_full[\"result\"], pdf_full[\"source_documents\"], emb_eval)\n",
        "\n",
        "    print(f\"Grounding similarity (cosine to retrieved context):\")\n",
        "    print(f\"  Neo4j: {neo_score:.3f}\")\n",
        "    print(f\"  PDF  : {pdf_score:.3f}\")\n",
        "    return {\"neo4j\": neo_score, \"pdf\": pdf_score}\n",
        "\n",
        "# Example:\n",
        "# compare_with_scores(\"Explain the UE registration flow and the NFs involved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kC7Cy7dDBU5",
        "outputId": "e543a3ae-e7d9-4e63-ba87-1a85f4225c51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grounding similarity (cosine to retrieved context):\n",
            "  Neo4j: 0.460\n",
            "  PDF  : 0.502\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'neo4j': 0.4596777566713459, 'pdf': 0.5021152072737562}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compare_with_scores(\"Enable each network function to declare the services it exposes, including version and supported protocols.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGLTRtI6DOxq",
        "outputId": "524d5071-f3ea-49ea-b9e4-fb7d0d7d8ccd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "QUESTION:\n",
            "Enable each network function to declare the services it exposes, including version and supported protocols.\n",
            "==========================================================================================\n",
            "[Neo4j] time: 11.66s\n",
            "To translate the high-level requirements for a 5G Core network into a YANG configuration, we need to\n",
            "define a YANG module that allows each network function to declare the services it exposes, including\n",
            "version and supported protocols. Below is a YANG configuration that adheres to the specified\n",
            "requirements.  ### YANG Module  ```yang module 5g-core-services {     yang-version 1.1;\n",
            "namespace \"urn:5g-core-services\";     prefix \"5gcs\";      import ietf-yang-types {         prefix\n",
            "\"yang\";     }      organization \"Your Organization\";     contact \"your.email@example.com\";\n",
            "description         \"This module defines the services exposed by network functions in a 5G Core\n",
            "network.\";      typedef protocol-type {         type enumeration {             enum \"HTTP\" {\n",
            "description \"Hypertext Transfer Protocol\";             }             enum \"HTTPS\" {\n",
            "description \"Hypertext Transfer Protocol Secure\";             }             enum \"REST\" {\n",
            "description \"Representational State Transfer\";             }             enum \"gRPC\" {\n",
            "description \"gRPC Protocol\";             }             enum \"WebSocket\" {\n",
            "description \"WebSocket Protocol\";             }             // Add more protocols as needed\n",
            "}     }      container network-functions {         list network-function {             key \"name\";\n",
            "leaf name {                 type string;                 description \"Name of the network\n",
            "function.\";             }             leaf version {                 type string;\n",
            "description \"Version of the network function.\";             }             list services {\n",
            "key \"service-name\";                 leaf service-name {                     type string;\n",
            "description \"Name of the service exposed by the network function.\";                 }\n",
            "leaf-list supported-protocols {                     type protocol-type;\n",
            "description \"Protocols supported by the service.\";                 }             }         }     } }\n",
            "```  ### Explanation of the YANG Configuration  1. **Module Definition**: The module is named\n",
            "`5g-core-services` and includes necessary metadata such as organization and contact information.  2.\n",
            "**Protocol Type**: A typedef `protocol-type` is defined using an enumeration to list the finite and\n",
            "controlled values for protocols that the network functions can support.  3. **Container for Network\n",
            "Functions**: A container named `network-functions` is created to hold a list of network functions.\n",
            "4. **Network Function List**: Each network function is represented as a list item with a unique key\n",
            "(`name`). It includes:    - `name`: The name of the network function.    - `version`: The version of\n",
            "the network function.    - `services`: A list of services exposed by the network function, each\n",
            "with:      - `service-name`: The name of the service.      - `supported-protocols`: A leaf-list that\n",
            "uses the `protocol-type` typedef to specify which protocols are supported.  ### Evidence Lines  -\n",
            "(4:8606e1fe-fb64-473a-89ee-50c8506f5ac1:5702|exampleFor|Use YANG 'enumeration' type when values are\n",
            "finite and controlled (e.g., protocols).) - (4:7e579923-d560-44db-\n",
            "bb2f-34f3325899f2:412|isSupportedVia|4:7e579923-d560-44db-bb2f-34f3325899f2:1560) -\n",
            "(4:7e579923-d560-44db-bb2f-34f3325899f2:5702|exampleFor|Use YANG 'enumeration' type when values are\n",
            "finite and controlled (e.g., protocols).) - (4:7e579923-d560-44db-\n",
            "bb2f-34f3325899f2:518|isImplementedVia|4:7e579923-d560-44db-bb2f-34f3325899f2:1322) - (4:8606e1fe-\n",
            "fb64-473a-89ee-50c8506f5ac1:2089|canExpose|4:8606e1fe-fb64-473a-89ee-50c8506f5ac1:2076) -\n",
            "(4:8606e1fe-fb64-473a-89ee-50c8506f5ac1:2006|exposes|4:8606e1fe-fb64-473a-89ee-50c8506f5ac1:1525)\n",
            "This YANG module is structured to meet the requirements and can be validated using the libyang tool.\n",
            "\n",
            "Sources (Neo4j):\n",
            " • Left: 4:8606e1fe-fb64-473a-89ee-50c8506f5ac1:5702 (Resource)\n",
            " • Left: 4:7e579923-d560-44db-bb2f-34f3325899f2:412 (Resource)\n",
            " • Left: 4:7e579923-d560-44db-bb2f-34f3325899f2:5702 (Resource)\n",
            " • Left: 4:7e579923-d560-44db-bb2f-34f3325899f2:518 (Resource)\n",
            " • Left: 4:8606e1fe-fb64-473a-89ee-50c8506f5ac1:2089 (Resource)\n",
            " • Left: 4:8606e1fe-fb64-473a-89ee-50c8506f5ac1:2006 (Resource)\n",
            "\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "[PDF]   time: 8.03s\n",
            "To translate the high-level requirement of enabling each network function to declare the services it\n",
            "exposes, including version and supported protocols, into a YANG configuration, we need to define a\n",
            "YANG module that captures these attributes. Below is a YANG model that adheres to the specified\n",
            "requirements and follows the rules for validation by the libyang tool.  ### YANG Module  ```yang\n",
            "module network-function-services {     yang-version 1.1;     namespace \"urn:network-function-\n",
            "services\";     prefix nfs;      import ietf-yang-types {         prefix yang;     }\n",
            "organization \"Your Organization Name\";     contact \"Your Contact Information\";      description\n",
            "\"This module defines the services exposed by network functions, including version and supported\n",
            "protocols.\";      revision 2023-10-01 {         description \"Initial revision.\";     }\n",
            "container network-functions {         description \"Container for network functions and their\n",
            "services.\";          list network-function {             key \"name\";             description \"List\n",
            "of network functions.\";              leaf name {                 type string;\n",
            "description \"Name of the network function.\";             }              leaf version {\n",
            "type string;                 description \"Version of the network function.\";             }\n",
            "list services {                 key \"service-name\";                 description \"List of services\n",
            "exposed by the network function.\";                  leaf service-name {                     type\n",
            "string;                     description \"Name of the service.\";                 }\n",
            "leaf service-version {                     type string;                     description \"Version of\n",
            "the service.\";                 }                  list supported-protocols {                     key\n",
            "\"protocol\";                     description \"Protocols supported by the service.\";\n",
            "leaf protocol {                         type string;                         description \"Name of\n",
            "the supported protocol.\";                     }                 }             }         }     } }\n",
            "```  ### Explanation of the YANG Model  1. **Module Definition**: The module is named `network-\n",
            "function-services` and includes necessary metadata such as namespace, prefix, organization, and\n",
            "contact information.  2. **Container**: The `network-functions` container holds all network\n",
            "functions.  3. **List of Network Functions**: The `network-function` list contains:    - `name`: The\n",
            "name of the network function.    - `version`: The version of the network function.  4. **List of\n",
            "Services**: Each network function can have multiple services defined in the `services` list, which\n",
            "includes:    - `service-name`: The name of the service.    - `service-version`: The version of the\n",
            "service.  5. **Supported Protocols**: Each service can support multiple protocols, defined in the\n",
            "`supported-protocols` list, which includes:    - `protocol`: The name of the supported protocol.\n",
            "### Evidence Lines  - (network-function-services|defines|network functions and their services) -\n",
            "(network-function|contains|name and version) - (services|exposes|service-name and service-version) -\n",
            "(supported-protocols|lists|protocols supported by the service)  This YANG model captures the\n",
            "requirement to declare services exposed by network functions, including their versions and supported\n",
            "protocols, in a structured and validated manner.\n",
            "\n",
            "Sources (PDF):\n",
            " • Tesi Asma Noor.pdf:p11 — Network Softwarisation    12 | P a g e     2.2.1.  Network Services in NFV    A network service can be viewed architecturally as a Forwarding Graph of  Virtual …\n",
            " • Tesi Asma Noor.pdf:p20 — Network Softwarisation    21 | P a g e     should not be aware of that change nor they should need to keep track of it. Th is  requires a decoupling that is pro…\n",
            " • 3493425.3502749.pdf:p6 — Technologies, Architectures, and Protocols for Computer Communication (New York, NY, USA, 2020), SIGCOMM ’20, Association for Computing Machinery, p. 648–661. […\n",
            " • RP_P9788770040020C5.pdf:p0 — volume between network functions for service provisioning and also the data trafﬁc, b) deﬁning the various data models coherent with the functioning of network …\n",
            " • Tesi Asma Noor.pdf:p11 — end point and a NF.   The deployment and operational behaviour requirements of each Network Service  is captured in a deployment template and stored during the …\n",
            " • Tesi Asma Noor.pdf:p5 — features, it can also receive an abstracted and global view of the network from the  controllers and use that information to provide appropriate guidance to the…\n",
            "\n",
            "==========================================================================================\n",
            "LLM JUDGE:\n",
            "```json\n",
            "{\n",
            "  \"winner\": \"neo4j\",\n",
            "  \"rationale\": \"Answer A provides a more structured and precise YANG configuration that adheres strictly to the requirements, including the use of an enumeration for supported protocols. It also includes a clear description of each component, ensuring better grounding to context and clarity in telecom terms. Answer B, while valid, introduces unnecessary complexity with additional fields and lacks the same level of clarity and adherence to YANG format best practices.\"\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "show_comparison(\"Enable each network function to declare the services it exposes, including version and supported protocols.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
